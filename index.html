<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Xianhui Meng, Xianhui Meng, Xianhui Meng, Xianhui Meng, Xianhui Meng, Xianhui Meng, ustc,  University of Science and Technology of China">
<meta name="description" content="Xianhui Meng">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Xianhui Meng's homepage, USTC</title>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
</head>
<body>
	
<nav class="navbar navbar-dark navbar-expand-lg fixed-top">
    <div id="layout-menu">
        <a href="#">Home</a>
        <a href="#biography">Biography</a>
		    <a href="#news">News</a>
		    <a href="#researches">Researches</a>
        <a href="#publications">Publications</a>
        <a href="#education">Education</a>
        <a href="#services">Services</a>
    </div>
</nav>
	
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1><font face="Arial"> Xianhui Meng </font></h1>
					<h1><font face="Arial"> ËíôË¥§Ëæâ </font></h1>
					 <!-- <h1><font face="Arial"> ËíôË¥§Ëæâ </font></h1> -->
				</div>

				<h3><font face="Arial"> M.S. Candidate </font></h3>
				<p><font face="Arial"> 
					University of Science and Technology of China, Anhui, China <br>
					
					<br>
					<em>Email: <a href="mailto:xzyr@mail.ustc.edu.cn">mengxh@mail.ustc.edu.cn</a></em> <br>
					
					<!-- <a href="https://xw-hu.github.io/XiaoweiHu.pdf"><em>[Curriculum Vitae]</em></a>
					&nbsp;&nbsp
					-->
				</font></p>
				<!--<p> <a href="https://scholar.google.com/citations?user=tUb4J0kAAAAJ&hl=en"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/xw-hu"><img src="./pic/github_s.jpg" height="20px" style="margin-bottom:-3px"></a>
					<a href="https://www.facebook.com/xiaowei.hu.102"><img src="./pic/Facebook_s.png" height="30px" style="margin-bottom:-3px"></a>
				</p> -->
			</td>
			<!-- <td>
				<img src="./images/own/QR_code.png" border="0" width="240"><br>
			</td> -->
		</tr><tr>
	</tr></tbody>
</table>



	
<div id="biography">
<h2><font face="Arial"> Biography </font></h2>
<p style="text-align:justify"><font face="Arial">
	
	I am currently a M.S. student in <a href="https://www.ustc.edu.cn/">University of Science and Technology of China (USTC) </a>,
	advised by Prof. <a href="http://staff.ustc.edu.cn/~junliu/">Jun Liu</a>. <br>
	<!-- I collaborate closely with Prof. <a href="https://faculty.hfut.edu.cn/liuliu/en/index.htm">Liu Liu</a>
	and Prof. <a href="https://scholar.google.com/citations?user=08U8joq2FOQC&hl=zh-CN&oi=sra">Jiankun Wang</a>. -->
	My research interests focus on computer vision and embodied AI, especially <strong>6D pose estimation</strong> and <strong>VLA</strong>.
	<!-- I actively collaborate with leading industry partners such as <a href="https://ailab.tencent.com">Tencent AI Lab</a>, <a href="https://www.iflytek.com">IFLYTEK</a>, <a href="https://www.astribot.com/">Astribot</a>,
	focusing on cutting-edge research in pose perception. -->
	I am a strong advocate of <strong>sharingüå±, collaboratingü§ù, advancingüöÄ, and innovatingüí°</strong>.
	Passionate about bridging fundamental research with real-world impact, I strive to ensure my work contributes to both academic progress and practical value.</p>

	<p><em><strong>If you're interested in collaborating or would like to connect, feel free to reach out via email (ÈÇÆÁÆ±Ôºömengxh@mail.ustc.edu.cn) </strong></em> üòä</p>




<div id="news">
<h2><font face="Arial"> News </font></h2>
<p style="text-align:justify"><font face="Arial">
<ul>
  <li><em>2025.03</em>:&nbsp;üéâüéâOne paper is accepted by ICME 2025!</li>
  <!-- <li><em>2025.02</em>:&nbsp;ü•≥ü•≥One paper is accepted by CVPR2025 See you in Nashville TN!</li>
  <li><em>2025.01</em>:&nbsp;üéâüéâOne paper is accepted by IEEE Transactions on Emerging Topics in Computational Intelligence (T-ETCI).</li>
  <li><em>2024.12</em>:&nbsp;üéâüéâOne paper is accepted by AAAI2025, See you in Pennsylvania!</li> -->
</ul>


<div id="researches">
<h2><font face="Arial">Researches </font></h2>
<p style="text-align:justify"><font face="Arial">

	My current research focuses on the visual perception of articulated and flexible objects,
	aiming to develop advanced 3D pose estimation methods to empower robots with fine manipulation and dexterous grasping capabilities.
	While significant progress has been made in enabling robotic operation in idealized settings,
	challenges related to robustness and adaptability persist in complex and unstructured environments such as underwater exploration, medical intervention, and industrial inspection.
	In response to the unique perception demands posed by these scenarios, I am actively expanding my research into new directions,
	with an emphasis on critical visual perception problems and corresponding solutions for underwater and medical robotics.

	
<div id="publications">
<h2><font face="Arial">Selected Publications </font>  
  <!-- <font face="Arial" size="3"><a href="https://scholar.google.com/citations?user=r5K6_ysAAAAJ&hl=zh-CN&oi=sra">[Google Scholar]</a></font>  -->
</h2>


<p><font face="Arial" size="4"><b>ICME 2025</b></font></p>

	<div align="center">
  <img src="./images/own/Diff-Art.png" width="700"/>
</div>

<ul>
  <li> <strong><em>Diff-Art: Category-level Articulation Pose  Estimation via Conditional Diffusion</em></strong>.</li>
</ul>

<p>Yukang Huo*, <strong>Xianhui Meng*</strong>, Li Zhang‚Ä†, Haonan Jiang, Yan Zhong, Mingyuan Yao and Haihua Wang‚Ä†</p>

<p>
  <a href="">[Paper]</a>
  <a href="">[BibTeX]</a>
  <a href="">[Project/Codes]</a>
</p>

<p><span style="color:red"><strong>[TL;DR:]</strong></span> <em>6D pose estimation via diffusion model.</em></p>


<!-- <p><font face="Arial" size="4"><b>AAAI 2025 (under review)</b></font></p>
<div align="center">
  <img src="./images/own/PPF_Tracker.png" width="700"/>
</div>

<ul>
  <li><strong><em>Exploring Category-level Articulated Object Pose Tracking on SE(3) Manifolds</em></strong>.</li>
</ul>

<p>W Xu, <strong>L Zhang</strong>, Q Li, Q Wu, L Wu, L Liu</p>

<p>
  <a href="">[Paper]</a>
  <a href="">[BibTeX]</a>
  <a href="https://github.com/xwb0117/ICAF-4">[Project/Codes]</a>
</p>

<p><span style="color:red"><strong>[TL;DR:]</strong></span> <em>An novel Integrated Framework for four mainstream articulation tasks.</em></p> -->



<p><font face="Arial" size="4"><b>TPAMI (under review)</b></font></p>
<div align="center">
  <img src="./images/own/TPAMI2025.png" width="700"/>
</div>

<ul>
  <li> <strong><em>Probing Effective and Efficient Category-Level Articulated Object Pose Perception</em></strong>.</li>
</ul>

<p>Li Zhang, <strong>Xianhui Meng</strong>, Liu Liu, Haonan Jiang, Jianan Wang, Rujing Wang, Cewu Lu, Jun Liu, Hong Zhang</p>

<p>
  <a href="">[Paper]</a>
  <a href="">[BibTeX]</a>
  <a href="https://sites.google.com/view/caperplusplus">[Project/Codes]</a>
</p>

<p><span style="color:red"><strong>[TL;DR:]</strong></span> <em>6D pose tracking by Rotation Decoupled strategy.</em></p>




<!-- <p><font face="Arial" size="4"><b>ACM MM 2024</b></font></p>
<div align="center">
  <img src="./images/own/MM24.png" width="700"/>
</div>

<ul>
  <li><strong><em>VoCAPTER: Voting-based Pose Tracking for Category-level Articulated Object via Inter-frame Priors</em></strong>.</li>
</ul>

<p><strong>L Zhang</strong>, Z Han, Y Zhong, Q Yu, X Wu, X Wang, R Wang</p>

<p>
  <a href="">[Paper]</a>
  <a href="">[BibTeX]</a>
  <a href="">[Project/Codes]</a>
</p>

<p><span style="color:red"><strong>[TL;DR:]</strong></span> <em>What serves as the bridge between pose estimation and pose tracking? Answer: inter-frame priors!</em></p> -->


	<!-- <p><font face="Arial" size="4"><b>NeurIPS 2024(spotlight)</b></font></p>
<div align="center">
  <img src="./images/own/nips24.png" width="700"/>
</div>

<ul>
  <li> <strong><em>Rethinking 3D Convolution in &ell;<sub>p</sub>-norm Space</em></strong>.</li>
</ul>

<p><strong>L Zhang</strong>, Y Zhong, J Wang, Z Min, R Wang, L Liu</p>

<p>
  <a href="">[Paper]</a>
  <a href="">[BibTeX]</a>
  <a href="">[Project/Codes]</a>
</p>

<p><span style="color:red"><strong>[TL;DR:]</strong></span> <em>Does 3D Convolution really need inner production? We made an exploration on &ell;<sub>p</sub>-norm convolution.</em></p> -->




	
	
<div id="education">
<h2><font face="Arial"> Education Experiences </h2>
	
<ul style="list-style-type:none">
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">

	<ul>
  <!-- <li>
    <em>2024.01 - 2025.01</em>, Astribot, Shenzhen, China. Topic: 6D pose estimation.
    (Supervisor: <a href="https://scholar.google.com/citations?user=mt5mvZ8AAAAJ&hl=zh-CN&oi=sra">Dr. Jianan Wang</a>)
  </li> -->

  <!-- <li>
    <em>2021.03 - 2021.10</em>, Tencent YouTu Lab, China. Topic: scene text localization, self-supervised learning.
    (Supervisor: Dr. Jason Liu, Deqiang Jiang)
  </li> -->

  <li>
    <em>2024.09 - Present</em>: M.S. degree in Information and Communication Engineering, University of Science and Technology of China, Hefei, China
  </li>
  <li>
    <em>2020.09 - 2024.07</em>: B.S. degree in Automation, Southeast University, Nanjing, China
  </li>  
</ul>

</p>
</ul>

<div id="services">
<h2><font face="Arial">Services </font></h2>
<p style="text-align:justify"><font face="Arial">

<!-- <p><font face="Arial" size="4"><b>Journal Reviewer</b></font></p>
<ul>
  <li>
    <strong>IEEE</strong>: IEEE Transactions on Pattern Analysis and Machine Intelligence (CCF-A),
    IEEE Transactions on Image Processing (CCF-A), IEEE Transactions on Mobile Computing (CCF-A),
    IEEE Transactions on Information Forensics and Security (CCF-A),
    IEEE Transactions on Neural Networks and Learning Systems, IEEE Transactions on Fuzzy Systems,
    IEEE Transactions on Cybernetics, IEEE Transactions on Multimedia,
    IEEE Transactions on Computational Social Systems, IEEE Internet of Things Journal,
    IEEE Transactions on Circuits and Systems for Video Technology,
    IEEE Transactions on Emerging Topics in Computational Intelligence, etc.
  </li>
  <li>
    <strong>ACM</strong>: ACM Transactions on Information Systems (CCF-A),
    ACM Transactions on Software Engineering and Methodology (CCF-A),
    ACM Transactions on Knowledge Discovery from Data,
    ACM Transactions on Intelligent Systems and Technology, etc.
  </li>
  <li>
    <strong>Springer</strong>: International Journal of Computer Vision (CCF-A),
    Cognitive Computation, etc.
  </li>
  <li>
    <strong>Elsevier</strong>: Artificial Intelligence (CCF-A),
    Information Fusion, Information Processing and Management,
    Neural Networks, Knowledge-Based Systems, Neurocomputing, etc.
  </li>
</ul> -->


<p><font face="Arial" size="4"><b>Conference Service</b></font></p>
<ul>
  <!-- <li><strong>Area Chair</strong>: IJCNN'25.</li>
  <li>
    <strong>Program Committee Member</strong>: CVPR23-25, ECCV24, ICCV23/25, AAAI22-25,
    ACM MM22-25, NIPS24-25, ICLR24, etc.
  </li> -->
  <li>
    <strong>Program Committee Member</strong>: ICME25, etc.
  </li>
</ul>

		


</body></html>

